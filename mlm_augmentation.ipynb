{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import AugmentDataSet\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/train.csv\"\n",
    "\n",
    "input_df = pd.read_csv(input_file)\n",
    "text_list = input_df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-base-v3-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(input_file)\n",
    "# train_df, valid_df = train_test_split(train_df, test_size=0.9, random_state=42)\n",
    "\n",
    "# train_df.to_csv(\"../data/train_10.csv\", index=False)\n",
    "# valid_df.to_csv(\"../data/valid_90.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:01<00:00, 5620.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = AugmentDataSet(text_list, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([    2, 22780,  4097,  9971,  7445,  7697,  4219, 22780, 24304, 10643,\n",
      "        28911,  4025,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_tokens(tokenizer, input_ids:torch.Tensor, mlm_prob:float=0.15, do_rep_random:bool=True):\n",
    "    '''\n",
    "        Copied from huggingface/transformers/data/data_collator - torch.mask_tokens()\n",
    "        Prepare masked tokens inputs/labels for masked language modeling\n",
    "        if do_rep_random is True:\n",
    "            80% MASK, 10% random, 10% original\n",
    "        else:\n",
    "            100% MASK\n",
    "    '''\n",
    "    labels = input_ids.clone()\n",
    "\n",
    "    probability_matrix = torch.full(labels.shape, mlm_prob)\n",
    "    special_tokens_mask = [\n",
    "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "    ]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value = 0.0)\n",
    "    if tokenizer._pad_token is not None:\n",
    "        padding_mask = labels.eq(tokenizer.pad_token_id)\n",
    "        probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -100 # We only compute loss on masked tokens\n",
    "\n",
    "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "    mask_rep_prob = 0.8\n",
    "    if not do_rep_random:\n",
    "        mask_rep_prob = 1.0\n",
    "    \n",
    "    indices_replaced = torch.bernoulli(torch.full(labels.shape, mask_rep_prob)).bool() & masked_indices\n",
    "    input_ids[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    if do_rep_random:\n",
    "        # 10% of the time, we replace masked input tokens with random word\n",
    "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
    "        random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
    "        input_ids[indices_random] = random_words[indices_random]\n",
    "\n",
    "    return input_ids, labels\n",
    "\n",
    "def candidate_filtering(tokenizer:AutoTokenizer,\n",
    "                        input_ids:list,\n",
    "                        idx:int,\n",
    "                        org:int,\n",
    "                        candidates:Union[list, torch.Tensor]) -> int:\n",
    "    '''\n",
    "    후보 필터링 조건에 만족하는 최적의 후보 선택\n",
    "    1. 원래 토큰과 후보 토큰이 같은 타입(is_same_token_type 참고)\n",
    "    2. 현 위치 앞 혹은 뒤에 동일한 토큰이 있지 않음\n",
    "    '''\n",
    "\n",
    "    org_token = tokenizer.convert_ids_to_tokens([org])[0]\n",
    "    candidate_tokens = tokenizer.convert_ids_to_tokens(candidates.cpu().tolist())\n",
    "\n",
    "    for rank, token in enumerate(candidate_tokens):\n",
    "        if org_token!=token and is_same_token_type(org_token, token):\n",
    "            if input_ids[idx-1]==candidates[rank] or input_ids[idx+1]==candidate_tokens[rank]:\n",
    "                continue\n",
    "            return candidates[rank]\n",
    "\n",
    "    return org\n",
    "\n",
    "def is_same_token_type(org_token:str, candidate:str) -> bool:\n",
    "    '''\n",
    "    후보 필터링 조건을 만족하는지 확인\n",
    "    - 후보와 원 토큰의 타입을 문장부호와 일반 토큰으로 나누어 같은 타입에 속하는지 확인\n",
    "    '''\n",
    "    res = False\n",
    "    if org_token[0]==\"#\" and org_token[2:].isalpha()==candidate.isalpha():\n",
    "        res = True\n",
    "    elif candidate[0]==\"#\" and org_token.isalpha()==candidate[2:].isalpha():\n",
    "        res = True\n",
    "    elif candidate[0]==\"#\" and org_token[0]==\"#\" and org_token[2:].isalpha()==candidate[2:].isalpha():\n",
    "        res = True\n",
    "    elif org_token.isalpha()==candidate.isalpha() and (candidate[0]!=\"#\" and org_token[0]!=\"#\"):\n",
    "        res = True\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_augment(model:AutoModelForMaskedLM,\n",
    "                tokenizer:AutoTokenizer,\n",
    "                dataset:torch.utils.data.Dataset,\n",
    "                k, threshold, mlm_prob, batch_size) -> str:\n",
    "    '''\n",
    "    배치 단위의 문장에 랜덤으로 마스킹을 적용하여 새로운 문장 배치를 생성(증강)\n",
    "\n",
    "    args:\n",
    "        model(AutoModelForMaskedLM)\n",
    "        tokenizer(AutoTokenizer)\n",
    "        dataset(torch.utils.data.Dataset)\n",
    "        dev(str or torch.device)\n",
    "        args(argparse.Namespace)\n",
    "            - k(int, default=5)\n",
    "            - threshold(float, default=0.95)\n",
    "           -  mlm_prob(float, default=0.15)\n",
    "        \n",
    "    return:\n",
    "        (list) : 증강한 문장들의 리스트\n",
    "    '''\n",
    "    dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "\n",
    "    augmented_res = []\n",
    "    dataloader = DataLoader(dataset, batch_size = batch_size)\n",
    "    for batch in tqdm.tqdm(dataloader):\n",
    "        #########################################################\n",
    "        # 인풋 문장에 랜덤으로 마스킹 적용\n",
    "        input_ids, attention_masks = batch[0], batch[1]\n",
    "        masked_input_ids, _ = mask_tokens(tokenizer, input_ids, mlm_prob, do_rep_random=False)\n",
    "\n",
    "        masked_input_ids = masked_input_ids.to(dev)\n",
    "        attention_masks = attention_masks.to(dev)\n",
    "        labels = input_ids\n",
    "        #########################################################\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(masked_input_ids, attention_mask = attention_masks)\n",
    "            logits1 = output[\"logits\"]\n",
    "\n",
    "        #########################################################\n",
    "        # 배치 내의 문장 별로 후보 필터링을 적용하고, 결과를 토대로 새로운 문장 생성\n",
    "        augmented1 = []\n",
    "        for sent_no in range(len(masked_input_ids)):\n",
    "            copied = copy.deepcopy(input_ids.cpu().tolist()[sent_no])\n",
    "\n",
    "            for i in range(len(masked_input_ids[sent_no])):\n",
    "                if masked_input_ids[sent_no][i] == tokenizer.pad_token_id:\n",
    "                    break\n",
    "\n",
    "                if masked_input_ids[sent_no][i] == tokenizer.mask_token_id:\n",
    "                    org_token = labels.cpu().tolist()[sent_no][i]\n",
    "                    prob = logits1[sent_no][i].softmax(dim=0)\n",
    "                    probability, candidates = prob.topk(k)\n",
    "                    if probability[0]<threshold:\n",
    "                        res = candidate_filtering(tokenizer, copied, i, org_token, candidates)\n",
    "                    else:\n",
    "                        res = candidates[0]\n",
    "                    copied[i] = res\n",
    "\n",
    "            copied = tokenizer.decode(copied, skip_special_tokens=True)\n",
    "            augmented1.append(copied)\n",
    "        #########################################################\n",
    "        augmented_res.extend(augmented1)\n",
    "\n",
    "    return augmented_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=256, out_features=768, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=768, out_features=35000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"monologg/koelectra-base-v3-generator\")\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [01:15<00:00, 92.17it/s]\n"
     ]
    }
   ],
   "source": [
    "augmented = batch_augment(model, tokenizer, dataset, 5, 0.95, 0.15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       ID                              text  target  \\\n",
      "0     ynat-v1_train_00000         개포2단지 분양 앞두고 개포지구 재건축 불붙어       1   \n",
      "1     ynat-v1_train_00001         삼성전자 KBIS 2018서 셰프컬렉션 선보여       0   \n",
      "2     ynat-v1_train_00002           LG G6 사면 BO 이어폰이 단돈 5천원       0   \n",
      "3     ynat-v1_train_00003            신간 블록체인혁명 2030·남자의 고독사       3   \n",
      "4     ynat-v1_train_00004    이스라엘 정보당국 팔레스타인인 50명 테러 혐의로 체포       4   \n",
      "...                   ...                               ...     ...   \n",
      "6995  ynat-v1_train_06995    힐만 SK 감독 고통스럽지만 내 상황 솔직히 알려야 해       5   \n",
      "6996  ynat-v1_train_06996    정의장 사드 국회동의 사안 아니라 쳐도 충분히 협의해야       6   \n",
      "6997  ynat-v1_train_06997          정치권 엘시티 수사 돌발변수에 촉각…왜 지금       6   \n",
      "6998  ynat-v1_train_06998   문 대통령 1987 관람…깜짝 방문에 객석 환호·박수종합       6   \n",
      "6999  ynat-v1_train_06999  120년 전 대한제국으로…가을밤 정동에서 시간 여행 떠나다       3   \n",
      "\n",
      "                                                    url                  date  \n",
      "0     https://news.naver.com/main/read.nhn?mode=LS2D...  2016.03.16. 오전 11:37  \n",
      "1     https://news.naver.com/main/read.nhn?mode=LS2D...   2018.01.10. 오전 8:33  \n",
      "2     https://news.naver.com/main/read.nhn?mode=LS2D...  2017.04.30. 오전 10:00  \n",
      "3     https://news.naver.com/main/read.nhn?mode=LS2D...  2019.06.13. 오전 11:49  \n",
      "4     https://news.naver.com/main/read.nhn?mode=LS2D...  2019.12.18. 오후 11:15  \n",
      "...                                                 ...                   ...  \n",
      "6995  https://sports.news.naver.com/news.nhn?oid=001...      2018.10.13 15:46  \n",
      "6996  https://news.naver.com/main/read.nhn?mode=LS2D...   2016.07.17. 오후 6:20  \n",
      "6997  https://news.naver.com/main/read.nhn?mode=LS2D...   2016.11.16. 오후 6:24  \n",
      "6998  https://news.naver.com/main/read.nhn?mode=LS2D...   2018.01.07. 오후 5:23  \n",
      "6999  https://news.naver.com/main/read.nhn?mode=LS2D...   2016.10.28. 오후 8:13  \n",
      "\n",
      "[7000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_id_prefix = \"aug_\"\n",
    "aug_url = \"mlm_augment\"\n",
    "aug_date = \"20240130\"\n",
    "\n",
    "augmented_df = pd.DataFrame({\"id\": [aug_id_prefix+str(i) for i in range(len(augmented))],\n",
    "                            \"text\": augmented,\n",
    "                            \"target\": input_df[\"target\"].tolist(),\n",
    "                            \"url\": [aug_url for i in range(len(augmented))],\n",
    "                            \"date\": [aug_date for i in range(len(augmented))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>개포2단지 분양 앞두고 개포지구 재건축 불붙어</td>\n",
       "      <td>1</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2016.03.16. 오전 11:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>삼성전자 KBIS 2018서 셰프컬렉션 선보여</td>\n",
       "      <td>0</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2018.01.10. 오전 8:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>LG G6 사면 BO 이어폰이 단돈 5천원</td>\n",
       "      <td>0</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2017.04.30. 오전 10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00003</td>\n",
       "      <td>신간 블록체인혁명 2030·남자의 고독사</td>\n",
       "      <td>3</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2019.06.13. 오전 11:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>이스라엘 정보당국 팔레스타인인 50명 테러 혐의로 체포</td>\n",
       "      <td>4</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2019.12.18. 오후 11:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                            text  target  \\\n",
       "0  ynat-v1_train_00000       개포2단지 분양 앞두고 개포지구 재건축 불붙어       1   \n",
       "1  ynat-v1_train_00001       삼성전자 KBIS 2018서 셰프컬렉션 선보여       0   \n",
       "2  ynat-v1_train_00002         LG G6 사면 BO 이어폰이 단돈 5천원       0   \n",
       "3  ynat-v1_train_00003          신간 블록체인혁명 2030·남자의 고독사       3   \n",
       "4  ynat-v1_train_00004  이스라엘 정보당국 팔레스타인인 50명 테러 혐의로 체포       4   \n",
       "\n",
       "                                                 url                  date  \n",
       "0  https://news.naver.com/main/read.nhn?mode=LS2D...  2016.03.16. 오전 11:37  \n",
       "1  https://news.naver.com/main/read.nhn?mode=LS2D...   2018.01.10. 오전 8:33  \n",
       "2  https://news.naver.com/main/read.nhn?mode=LS2D...  2017.04.30. 오전 10:00  \n",
       "3  https://news.naver.com/main/read.nhn?mode=LS2D...  2019.06.13. 오전 11:49  \n",
       "4  https://news.naver.com/main/read.nhn?mode=LS2D...  2019.12.18. 오후 11:15  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aug_0</td>\n",
       "      <td>##2단지 분양 앞두고 개포 · 재건축 불붙어</td>\n",
       "      <td>1</td>\n",
       "      <td>mlm_augment</td>\n",
       "      <td>20240130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aug_1</td>\n",
       "      <td>삼성전자 KBIS 2018서 셰프컬렉션 선보여</td>\n",
       "      <td>0</td>\n",
       "      <td>mlm_augment</td>\n",
       "      <td>20240130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aug_2</td>\n",
       "      <td>LG G6 사면 BO 이어폰이 단 5천원</td>\n",
       "      <td>0</td>\n",
       "      <td>mlm_augment</td>\n",
       "      <td>20240130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aug_3</td>\n",
       "      <td>② 블록체인혁명 2030, 남자의 고독사</td>\n",
       "      <td>3</td>\n",
       "      <td>mlm_augment</td>\n",
       "      <td>20240130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aug_4</td>\n",
       "      <td>이스라엘 정보, 팔레스타인인 50명 테러 혐의로 체포</td>\n",
       "      <td>4</td>\n",
       "      <td>mlm_augment</td>\n",
       "      <td>20240130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                           text  target          url      date\n",
       "0  aug_0      ##2단지 분양 앞두고 개포 · 재건축 불붙어       1  mlm_augment  20240130\n",
       "1  aug_1      삼성전자 KBIS 2018서 셰프컬렉션 선보여       0  mlm_augment  20240130\n",
       "2  aug_2         LG G6 사면 BO 이어폰이 단 5천원       0  mlm_augment  20240130\n",
       "3  aug_3         ② 블록체인혁명 2030, 남자의 고독사       3  mlm_augment  20240130\n",
       "4  aug_4  이스라엘 정보, 팔레스타인인 50명 테러 혐의로 체포       4  mlm_augment  20240130"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([input_df, augmented_df], axis=0)\n",
    "concat_df.to_csv(\"../data/mlm_aug_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "klue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
